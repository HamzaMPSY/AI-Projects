{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1hHJoEJ7LQyuFMNh_VbfQktSG8W6pHWvB",
      "authorship_tag": "ABX9TyMOgIGeCGwpRXEP9pBR7TeG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HamzaMPSY/AI-Projects/blob/master/autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xrYMWmkwVwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os \n",
        "import cv2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint \n",
        "from keras.utils import plot_model\n",
        "from keras.models import model_from_json\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0xP8ZxWhngL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = (160,160,3) # Image dimension\n",
        "BATCH_SIZE = 64\n",
        "Z_DIM = 128 # Dimension of the latent vector (z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBUz-_stjnqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ddc3cea-19c5-4669-a802-cb7d58b300fa"
      },
      "source": [
        "cd drive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihs4fQvl58_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = np.load('utkfacesdata_160.npy')\n",
        "images = np.transpose(images,(0,2,3,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd0PlLIfEAF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(images[3,...])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9J6lqfdkHAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
        "\t\"\"\"\n",
        "\tfunction that normalize an np.array \n",
        "\t\"\"\"\n",
        "\toutput = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n",
        "\treturn output\n",
        "\n",
        "def preprocess(x):\n",
        "\t\"\"\"\n",
        "\tfunction to preprocess an image or array of images\n",
        "\t\"\"\"\n",
        "\tif x.ndim == 4:\n",
        "\t    axis = (1, 2, 3)\n",
        "\t    size = x[0].size\n",
        "\telif x.ndim == 3:\n",
        "\t    axis = (0, 1, 2)\n",
        "\t    size = x.size\n",
        "\telse:\n",
        "\t    raise ValueError('Dimension should be 3 or 4')\n",
        "\n",
        "\tmean = np.mean(x, axis=axis, keepdims=True)\n",
        "\tstd = np.std(x, axis=axis, keepdims=True)\n",
        "\tstd_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
        "\ty = (x - mean) / std_adj\n",
        "\treturn y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6kKnhiMkJq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(images.shape[0]):\n",
        "  images[i,...] = preprocess(images[i,...])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWUZcv6PeGtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ENCODER\n",
        "def build_encoder(input_dim, output_dim, conv_filters, use_batch_norm = True, use_dropout = True):\n",
        "  global K\n",
        "  K.clear_session()\n",
        "  # Number of Conv layers\n",
        "  n_layers = len(conv_filters)\n",
        "  # Define model input\n",
        "  encoder_input = Input(shape = input_dim, name = 'encoder_input')\n",
        "  x = encoder_input\n",
        "  # Add convolutional layers\n",
        "  for i in range(n_layers):\n",
        "      x = Conv2D(filters = conv_filters[i],kernel_size=3,strides=2,padding = 'same',name = 'encoder_conv_' + str(i))(x)\n",
        "      if use_batch_norm:\n",
        "        x = BatchNormalization()(x)\n",
        "      x = LeakyReLU()(x)\n",
        "      if use_dropout:\n",
        "        x = Dropout(rate=0.25)(x)\n",
        "  shape_before_flattening = K.int_shape(x)[1:] \n",
        "  x = Flatten()(x)\n",
        "  encoder_output = Dense(Z_DIM)(x)\n",
        "  return encoder_input, encoder_output ,shape_before_flattening, Model(encoder_input, encoder_output)\n",
        "\n",
        "encoder_input, encoder_output,shape_before_flattening, encoder  = build_encoder(input_dim = INPUT_DIM,output_dim = Z_DIM,conv_filters = [32, 64])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlUK6vmFvTUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(shape_before_flattening)\n",
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iOoXX9UdlKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_decoder(input_dim, shape_before_flattening, conv_filters):\n",
        "\n",
        "  # Number of Conv layers\n",
        "  n_layers = len(conv_filters)\n",
        "\n",
        "  # Define model input\n",
        "  decoder_input = Input(shape = (input_dim,) , name = 'decoder_input')\n",
        "\n",
        "  # To get an exact mirror image of the encoder\n",
        "  x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "  x = Reshape(shape_before_flattening)(x)\n",
        "\n",
        "  # Add convolutional layers\n",
        "  for i in range(n_layers):\n",
        "      x = Conv2DTranspose(filters = conv_filters[i], kernel_size = (3,3),strides=2,padding = 'same',name = 'decoder_conv_' + str(i))(x)\n",
        "      # Adding a sigmoid layer at the end to restrict the outputs \n",
        "      # between 0 and 1\n",
        "      if i < n_layers - 1:\n",
        "        x = LeakyReLU()(x)\n",
        "      else:\n",
        "        x = Activation('sigmoid')(x)\n",
        "\n",
        "  # Define model output\n",
        "  decoder_output = x\n",
        "\n",
        "  return decoder_input, decoder_output, Model(decoder_input, decoder_output)\n",
        "\n",
        "\n",
        "decoder_input, decoder_output, decoder = build_decoder(input_dim = Z_DIM,\n",
        "                                        shape_before_flattening = shape_before_flattening,\n",
        "                                        conv_filters = [32,3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNowdrYHzK7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder.summary()\n",
        "plot_model(decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yclNZvkVgEEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The input to the model will be the image fed to the encoder.\n",
        "input = encoder_input\n",
        "\n",
        "# Output will be the output of the decoder. The term - decoder(encoder_output) \n",
        "# combines the model by passing the encoder output to the input of the decoder.\n",
        "output = decoder(encoder_output)\n",
        "\n",
        "# Input to the combined model will be the input to the encoder.\n",
        "# Output of the combined model will be the output of the decoder.\n",
        "model = Model(input, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vffQ18ngyrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()\n",
        "plot_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXkvqjrUxNn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_EPOCHS = 100\n",
        "model.compile(optimizer='adadelta',loss='binary_crossentropy')\n",
        "model.fit(images,images,epochs=N_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-yYCMKlCUOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadModel():\n",
        "\tjson_file = open('vae_model.json', 'r')\n",
        "\tloaded_model_json = json_file.read()\n",
        "\tjson_file.close()\n",
        "\tloaded_model = model_from_json(loaded_model_json)\n",
        "\t# load weights into new model\n",
        "\tloaded_model.load_weights(\"vae_model.h5\")\n",
        "\tprint(\"Loaded model from disk\")\n",
        "\treturn loaded_model\n",
        "\n",
        "vae_model = loadModel()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w6Q-ubYi-1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_compare_vae(images=None):\n",
        "  \n",
        "  if images is None:\n",
        "    example_batch = next(train_generator)\n",
        "    example_batch = example_batch[0]\n",
        "    images = example_batch[:10]\n",
        "\n",
        "  n_to_show = images.shape[0]\n",
        "  reconst_images = model.predict(images)\n",
        "\n",
        "  fig = plt.figure(figsize=(15, 3))\n",
        "  \n",
        "  for i in range(n_to_show):\n",
        "      img = images[i].squeeze()\n",
        "      sub = fig.add_subplot(2, n_to_show, i+1)\n",
        "      sub.axis('off')        \n",
        "      sub.imshow(img)\n",
        "\n",
        "  for i in range(n_to_show):\n",
        "      img = reconst_images[i].squeeze()\n",
        "      sub = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n",
        "      sub.axis('off')\n",
        "      sub.imshow(img)  \n",
        "\n",
        "plot_compare_vae(images[0:6]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0fxR_r_VtmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = encoder.predict(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN2PyJWZvGNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# serialize classifier to JSON\n",
        "classifier_json = encoder.to_json()\n",
        "with open(\"encoder_mpsy.json\", \"w\") as json_file:\n",
        "    json_file.write(classifier_json)\n",
        "# serialize weights to HDF5\n",
        "encoder.save_weights(\"encoder_mpsy.h5\")\n",
        "print(\"Saved classifier to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeH8cehLvHHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.linalg.norm(a[0] - a[-2]),np.linalg.norm(a[-1] - a[-2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-9IMUQmvoiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl6MlFDEvprD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# serialize classifier to JSON\n",
        "classifier_json = decoder.to_json()\n",
        "with open(\"decodermpsy.json\", \"w\") as json_file:\n",
        "    json_file.write(classifier_json)\n",
        "# serialize weights to HDF5\n",
        "decoder.save_weights(\"decodermpsy.h5\")\n",
        "print(\"Saved classifier to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvjdkcGby1gU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"embeddings.npy\",a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1XY9KE8ywKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}